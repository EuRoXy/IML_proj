{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir(\"food\")\n",
    "file_names.sort()\n",
    "#print(file_names)\n",
    "print('The number of food images: ', len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load training train_triplets\n",
    "train_triplets = np.loadtxt('train_triplets.txt', dtype=int)\n",
    "print(train_triplets.shape)\n",
    "print(train_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train_triplets.copy()\n",
    "#np.random.seed(617)\n",
    "np.random.seed(618)\n",
    "np.random.shuffle(train)\n",
    "Y_train = np.random.randint(2, size=len(train_triplets))\n",
    "print(train.shape, train[0:10])\n",
    "print(Y_train.shape, Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "#EPOCHS = 15\n",
    "EPOCHS = 100\n",
    "\n",
    "n_total = len(train_triplets)\n",
    "#n_train = int(0.85*n_total - 0.85*n_total % BATCH_SIZE)\n",
    "n_train = n_total - n_total % BATCH_SIZE\n",
    "n_valid = (n_total - n_train) - (n_total - n_train) % BATCH_SIZE\n",
    "print(n_total, n_train, n_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include_top=False: exclude top(last) 3 fully-connected layers. get features dim=(1,7,7,512)\n",
    "VGG = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_drop = 0.2\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(3, 7, 7, 512)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(r_drop),\n",
    "    \n",
    "    Dense(4096, activation='relu', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(r_drop),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.save_weights('ann')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_history = np.array([])\n",
    "val_acc_history = np.array([])\n",
    "model.load_weights('ann_trained')\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for s in range(0, n_train, BATCH_SIZE):\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    features_array = np.array([])\n",
    "    for i in range(s, s+BATCH_SIZE):\n",
    "        \n",
    "        X_img = np.array([])\n",
    "        for j in [0, 1+Y_train[i], 2-Y_train[i]]:\n",
    "        \n",
    "            #load image\n",
    "            img_raw = load_img('food/' + str(train[i][j]).zfill(5) + '.jpg', target_size=(224, 224))\n",
    "            #plt.imshow(img_crop)\n",
    "            #plt.show()\n",
    "            img_crop = img_to_array(img_raw)\n",
    "        \n",
    "            # convert input to VGG format\n",
    "            img_crop = preprocess_input(img_crop)\n",
    "        \n",
    "            X_img = np.append(X_img, img_crop)\n",
    "        \n",
    "        X_img = X_img.reshape(3, 224, 224, 3)\n",
    "        \n",
    "\n",
    "        # use VGG to extract features (4D input)\n",
    "        features = VGG.predict(X_img)\n",
    "    \n",
    "        features_array = np.append(features_array, features)\n",
    "        \n",
    "    features_array = features_array.reshape(BATCH_SIZE, 3, 7, 7, 512)\n",
    "    \n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "    history = model.fit(features_array[:BATCH_SIZE], np.array(Y_train[s:s+BATCH_SIZE]), \\\n",
    "                        batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "    acc_history = np.append(acc_history, history.history['accuracy'])\n",
    "    #val_acc_history = np.append(val_acc_history, history.history['val_accuracy'])\n",
    "\n",
    "    t3 = time.perf_counter()\n",
    "    total_time += t3 - t1\n",
    "    print('s = ', s, 'Loading time = %.3f' %(t2 - t1), 'Training time = %.3f' %(t3 - t2), 'Total time = %.3f' %(total_time))\n",
    "    #print('validation accuacry = %.4f' %(val_acc_history[-1]))\n",
    "    \n",
    "    if (s % 100*BATCH_SIZE) == 0:\n",
    "        model.save_weights('ann_trained')\n",
    "        print('weights saved at %.1f s' %(total_time))\n",
    "        \n",
    "model.save_weights('ann_trained')\n",
    "print('Total time = %.3f' %(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(acc_history, label='accuracy')\n",
    "plt.plot(val_acc_history, label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('ann_trained')\n",
    "Y_hat = np.array([])\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for s in range(n_train, n_train+n_valid, BATCH_SIZE):\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    features_array = np.array([])\n",
    "    for i in range(s, s+BATCH_SIZE):\n",
    "        \n",
    "        X_img = np.array([])\n",
    "        for j in [0, 1+Y_train[i], 2-Y_train[i]]:\n",
    "        \n",
    "            #load image\n",
    "            img_raw = load_img('food/' + str(train[i][j]).zfill(5) + '.jpg', target_size=(224, 224))\n",
    "            #plt.imshow(img_crop)\n",
    "            #plt.show()\n",
    "            img_crop = img_to_array(img_raw)\n",
    "        \n",
    "            # convert input to VGG format\n",
    "            img_crop = preprocess_input(img_crop)\n",
    "        \n",
    "            X_img = np.append(X_img, img_crop)\n",
    "        \n",
    "        X_img = X_img.reshape(3, 224, 224, 3)\n",
    "\n",
    "        # use VGG to extract features (4D input)\n",
    "        features = VGG.predict(X_img)\n",
    "    \n",
    "        features_array = np.append(features_array, features)\n",
    "        \n",
    "    features_array = features_array.reshape(BATCH_SIZE, 3, 7, 7, 512)\n",
    "\n",
    "    Y_hat = np.append(Y_hat, model.predict_classes(features_array[:BATCH_SIZE]))\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    total_time += t2 - t1\n",
    "    print('s = ', s, 'Loading time = %.3f' %(t2 - t1), 'Total time = %.3f' %(total_time))\n",
    "        \n",
    "print('Total time = %.3f' %(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape, Y_hat.shape)\n",
    "print(accuracy_score(Y_train[:n_train], Y_hat))\n",
    "print(accuracy_score(Y_train[n_train:n_train+n_valid], Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triplets = np.loadtxt('test_triplets.txt', dtype=int)\n",
    "n_test = len(test_triplets)\n",
    "print(test_triplets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('ann_trained')\n",
    "Y_hat = np.array([])\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    X_img = np.array([])\n",
    "    for j in [0, 1, 2]:\n",
    "        \n",
    "        #load image\n",
    "        img_raw = load_img('food/' + str(test_triplets[i][j]).zfill(5) + '.jpg', target_size=(224, 224))\n",
    "        #plt.imshow(img_crop)\n",
    "        #plt.show()\n",
    "        img_crop = img_to_array(img_raw)\n",
    "        \n",
    "        # convert input to VGG format\n",
    "        img_crop = preprocess_input(img_crop)\n",
    "        \n",
    "        X_img = np.append(X_img, img_crop)\n",
    "        \n",
    "    X_img = X_img.reshape(3, 224, 224, 3)\n",
    "\n",
    "    # use VGG to extract features (4D input)\n",
    "    features = VGG.predict(X_img)\n",
    "    \n",
    "    # flatten as one dimension\n",
    "    features_compress = features.reshape(1, 3, 7, 7, 512)\n",
    "\n",
    "    Y_hat = np.append(Y_hat, (model.predict(features_compress) < 0.5).astype(int) )\n",
    "    \n",
    "    t2 = time.perf_counter()\n",
    "    total_time += t2 - t1\n",
    "    if i % 2000 == 0:\n",
    "        print('i = ', i, 'Loading time = %.3f' %(t2 - t1), 'Total time = %.3f' %(total_time))\n",
    "    \n",
    "print('Total time = %.3f' %(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"labels.csv\", Y_hat, fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
